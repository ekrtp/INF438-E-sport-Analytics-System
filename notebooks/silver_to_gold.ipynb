{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fd36e",
   "metadata": {},
   "outputs": [],
   "source": "# Notebook: Silver to Gold Aggregation\n# Purpose: Read data from Silver layer and aggregate it into Gold layer\n\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.window import Window\nimport os\n\nstorage_account = \"dota2lakehousenew\"\ncontainer = \"data\"\nstorage_account_key = os.environ.get(\"AZURE_STORAGE_KEY\")\n\nspark.conf.set(\n    f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\",\n    storage_account_key\n)\n\nSILVER_PATH = f\"abfss://{container}@{storage_account}.dfs.core.windows.net/silver\"\nGOLD_PATH = f\"abfss://{container}@{storage_account}.dfs.core.windows.net/gold\"\n\nprint(\"Silver to Gold aggregation started\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f22c78",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nLoading data from Silver layer...\")\n\ndf_matches = spark.read.format(\"delta\").load(f\"{SILVER_PATH}/cleaned_matches\")\ndf_players = spark.read.format(\"delta\").load(f\"{SILVER_PATH}/cleaned_players\")\ndf_picks_bans = spark.read.format(\"delta\").load(f\"{SILVER_PATH}/cleaned_picks_bans\")\n\nprint(f\"Matches: {df_matches.count():,} rows\")\nprint(f\"Players: {df_players.count():,} rows\")\nprint(f\"Picks/Bans: {df_picks_bans.count():,} rows\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c77d86a",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nCreating Player Statistics...\")\n\ndf_players_valid = df_players.filter(col(\"is_outlier\") == False)\n\ndf_player_stats = df_players_valid \\\n    .filter(col(\"account_id\").isNotNull()) \\\n    .groupBy(\"account_id\") \\\n    .agg(\n        count(\"match_id\").alias(\"total_matches\"),\n        sum(\"win\").alias(\"total_wins\"),\n        round(avg(\"kills\"), 2).alias(\"avg_kills\"),\n        round(avg(\"deaths\"), 2).alias(\"avg_deaths\"),\n        round(avg(\"assists\"), 2).alias(\"avg_assists\"),\n        round(avg(\"kda_calculated\"), 2).alias(\"avg_kda\"),\n        sum(\"kills\").alias(\"total_kills\"),\n        sum(\"deaths\").alias(\"total_deaths\"),\n        sum(\"assists\").alias(\"total_assists\"),\n        round(avg(\"gold_per_min\"), 2).alias(\"avg_gpm\"),\n        round(avg(\"xp_per_min\"), 2).alias(\"avg_xpm\"),\n        round(avg(\"hero_damage\"), 0).alias(\"avg_hero_damage\"),\n        round(avg(\"tower_damage\"), 0).alias(\"avg_tower_damage\"),\n        round(avg(\"last_hits\"), 2).alias(\"avg_last_hits\"),\n        countDistinct(\"hero_id\").alias(\"unique_heroes_played\"),\n        first(\"personaname\").alias(\"last_known_name\"),\n        max(\"rank_tier\").alias(\"highest_rank\")\n    )\n\ndf_player_stats = df_player_stats \\\n    .withColumn(\"win_rate\", round(col(\"total_wins\") / col(\"total_matches\") * 100, 2)) \\\n    .withColumn(\"calculated_at\", current_timestamp())\n\nwindow_kda = Window.orderBy(desc(\"avg_kda\"))\nwindow_winrate = Window.orderBy(desc(\"win_rate\"))\n\ndf_player_stats = df_player_stats \\\n    .withColumn(\"kda_rank\", row_number().over(window_kda)) \\\n    .withColumn(\"winrate_rank\", row_number().over(window_winrate))\n\nprint(f\"Player stats created: {df_player_stats.count():,} unique players\")\ndf_player_stats.select(\"account_id\", \"total_matches\", \"avg_kda\", \"win_rate\", \"kda_rank\").show(10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661b418",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nCreating Hero Statistics (Meta Analysis)...\")\n\ndf_hero_performance = df_players_valid \\\n    .groupBy(\"hero_id\") \\\n    .agg(\n        count(\"match_id\").alias(\"times_played\"),\n        sum(\"win\").alias(\"wins\"),\n        round(avg(\"kills\"), 2).alias(\"avg_kills\"),\n        round(avg(\"deaths\"), 2).alias(\"avg_deaths\"),\n        round(avg(\"assists\"), 2).alias(\"avg_assists\"),\n        round(avg(\"kda_calculated\"), 2).alias(\"avg_kda\"),\n        round(avg(\"gold_per_min\"), 2).alias(\"avg_gpm\"),\n        round(avg(\"xp_per_min\"), 2).alias(\"avg_xpm\"),\n        round(avg(\"hero_damage\"), 0).alias(\"avg_hero_damage\"),\n        round(avg(\"tower_damage\"), 0).alias(\"avg_tower_damage\")\n    ) \\\n    .withColumn(\"win_rate\", round(col(\"wins\") / col(\"times_played\") * 100, 2))\n\ndf_pick_stats = df_picks_bans \\\n    .filter(col(\"is_pick\") == True) \\\n    .groupBy(\"hero_id\") \\\n    .agg(count(\"*\").alias(\"pick_count\"))\n\ndf_ban_stats = df_picks_bans \\\n    .filter(col(\"is_pick\") == False) \\\n    .groupBy(\"hero_id\") \\\n    .agg(count(\"*\").alias(\"ban_count\"))\n\ndf_hero_stats = df_hero_performance \\\n    .join(df_pick_stats, \"hero_id\", \"left\") \\\n    .join(df_ban_stats, \"hero_id\", \"left\") \\\n    .fillna({\"pick_count\": 0, \"ban_count\": 0}) \\\n    .withColumn(\"total_presence\", col(\"pick_count\") + col(\"ban_count\")) \\\n    .withColumn(\"calculated_at\", current_timestamp())\n\ntotal_matches = df_matches.count()\ndf_hero_stats = df_hero_stats \\\n    .withColumn(\"presence_rate\", round(col(\"total_presence\") / (total_matches * 2) * 100, 2)) \\\n    .withColumn(\"meta_tier\",\n        when(col(\"presence_rate\") > 50, \"S-Tier\")\n        .when(col(\"presence_rate\") > 30, \"A-Tier\")\n        .when(col(\"presence_rate\") > 15, \"B-Tier\")\n        .when(col(\"presence_rate\") > 5, \"C-Tier\")\n        .otherwise(\"D-Tier\")\n    )\n\nprint(f\"Hero stats created: {df_hero_stats.count()} heroes\")\ndf_hero_stats.orderBy(desc(\"presence_rate\")).select(\n    \"hero_id\", \"times_played\", \"win_rate\", \"pick_count\", \"ban_count\", \"presence_rate\", \"meta_tier\"\n).show(10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0906fe",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nCreating Match Analytics...\")\n\ndf_daily_stats = df_matches \\\n    .groupBy(\"match_date\") \\\n    .agg(\n        count(\"match_id\").alias(\"match_count\"),\n        round(avg(\"duration_minutes\"), 2).alias(\"avg_duration\"),\n        round(avg(\"total_kills\"), 2).alias(\"avg_total_kills\"),\n        sum(when(col(\"radiant_win\") == True, 1).otherwise(0)).alias(\"radiant_wins\"),\n        sum(when(col(\"radiant_win\") == False, 1).otherwise(0)).alias(\"dire_wins\"),\n        sum(when(col(\"is_stomp\") == True, 1).otherwise(0)).alias(\"stomp_games\")\n    ) \\\n    .withColumn(\"radiant_win_rate\", round(col(\"radiant_wins\") / col(\"match_count\") * 100, 2)) \\\n    .orderBy(\"match_date\")\n\nprint(f\"Daily stats: {df_daily_stats.count()} days of data\")\n\ndf_duration_analysis = df_matches \\\n    .withColumn(\"duration_bucket\",\n        when(col(\"duration_minutes\") < 25, \"Very Short (<25min)\")\n        .when(col(\"duration_minutes\") < 35, \"Short (25-35min)\")\n        .when(col(\"duration_minutes\") < 45, \"Medium (35-45min)\")\n        .when(col(\"duration_minutes\") < 55, \"Long (45-55min)\")\n        .otherwise(\"Very Long (>55min)\")\n    ) \\\n    .groupBy(\"duration_bucket\") \\\n    .agg(\n        count(\"match_id\").alias(\"match_count\"),\n        round(avg(\"total_kills\"), 2).alias(\"avg_kills\"),\n        sum(when(col(\"radiant_win\") == True, 1).otherwise(0)).alias(\"radiant_wins\")\n    ) \\\n    .withColumn(\"radiant_win_rate\", round(col(\"radiant_wins\") / col(\"match_count\") * 100, 2))\n\nprint(\"\\nDuration Analysis:\")\ndf_duration_analysis.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688c18e",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nCreating ML Feature Table...\")\n\ndf_ml_features = df_players_valid \\\n    .join(\n        df_matches.select(\n            \"match_id\", \"duration_minutes\", \"match_hour\", \n            \"match_day_of_week\", \"radiant_win\", \"game_mode\", \"region\"\n        ),\n        \"match_id\",\n        \"inner\"\n    ) \\\n    .select(\n        \"match_id\", \"account_id\", \"hero_id\",\n        \"kills\", \"deaths\", \"assists\", \"kda_calculated\",\n        \"gold_per_min\", \"xp_per_min\", \"hero_damage\", \"tower_damage\",\n        \"last_hits\", \"denies\", \"level\",\n        \"lane\", \"lane_role\",\n        \"duration_minutes\", \"match_hour\", \"match_day_of_week\",\n        \"game_mode\", \"region\",\n        \"win\"\n    )\n\nprint(f\"ML features created: {df_ml_features.count():,} rows\")\nprint(f\"Feature columns: {len(df_ml_features.columns)}\")\ndf_ml_features.printSchema()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a898e897",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nWriting to Gold Layer...\")\n\ndf_player_stats.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_PATH}/player_stats\")\nprint(\"Player stats written\")\n\ndf_hero_stats.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_PATH}/hero_stats\")\nprint(\"Hero stats written\")\n\ndf_daily_stats.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_PATH}/daily_stats\")\nprint(\"Daily stats written\")\n\ndf_ml_features.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_PATH}/ml_features\")\nprint(\"ML features written\")\n\nprint(\"\\nGold layer complete\")"
  },
  {
   "cell_type": "code",
   "id": "a1qzkot1v27",
   "source": "print(\"\\nExporting CSV samples from Gold Layer...\")\n\nfrom pyspark.sql.functions import rand\nfrom datetime import datetime\n\nSAMPLES_PATH = f\"{GOLD_PATH}/samples\"\ntimestamp = datetime.now().strftime(\"%Y%m%d\")\n\nprint(\"Exporting all player stats...\")\nplayer_count = df_player_stats.count()\nplayer_stats_file = f\"{SAMPLES_PATH}/gold_player_stats_complete_{player_count}rows_{timestamp}.csv\"\ndf_player_stats.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(player_stats_file)\nprint(f\"  Written {player_count:,} rows\")\n\nprint(\"Exporting all hero stats...\")\nhero_count = df_hero_stats.count()\nhero_stats_file = f\"{SAMPLES_PATH}/gold_hero_stats_complete_{hero_count}rows_{timestamp}.csv\"\ndf_hero_stats.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(hero_stats_file)\nprint(f\"  Written {hero_count:,} rows\")\n\nprint(\"Exporting all daily stats...\")\ndaily_count = df_daily_stats.count()\ndaily_stats_file = f\"{SAMPLES_PATH}/gold_daily_stats_complete_{daily_count}rows_{timestamp}.csv\"\ndf_daily_stats.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(daily_stats_file)\nprint(f\"  Written {daily_count:,} rows\")\n\nprint(\"Exporting stratified ML features sample...\")\nML_SAMPLE_SIZE = 5000\ntotal_ml_count = df_ml_features.count()\n\nif total_ml_count > ML_SAMPLE_SIZE:\n    wins_sample = df_ml_features.filter(col(\"win\") == 1).orderBy(rand(seed=42)).limit(ML_SAMPLE_SIZE // 2)\n    loses_sample = df_ml_features.filter(col(\"win\") == 0).orderBy(rand(seed=42)).limit(ML_SAMPLE_SIZE // 2)\n    ml_sample = wins_sample.union(loses_sample).orderBy(rand(seed=42))\n    print(f\"  Stratified: {ML_SAMPLE_SIZE // 2} wins + {ML_SAMPLE_SIZE // 2} losses\")\nelse:\n    ml_sample = df_ml_features\n    ML_SAMPLE_SIZE = total_ml_count\n    print(f\"  Using all {total_ml_count:,} rows\")\n\nml_features_file = f\"{SAMPLES_PATH}/gold_ml_features_sample_{ML_SAMPLE_SIZE}rows_{timestamp}.csv\"\nml_sample.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(ml_features_file)\nprint(f\"  Written {ML_SAMPLE_SIZE:,} rows\")\n\nprint(\"\\nGold samples exported successfully\")\nprint(f\"Location: {SAMPLES_PATH}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487425e",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nCreating SQL tables...\")\n\nspark.sql(\"CREATE DATABASE IF NOT EXISTS esports_gold\")\n\nspark.sql(f\"\"\"\n    CREATE TABLE IF NOT EXISTS esports_gold.player_stats\n    USING DELTA\n    LOCATION '{GOLD_PATH}/player_stats'\n\"\"\")\n\nspark.sql(f\"\"\"\n    CREATE TABLE IF NOT EXISTS esports_gold.hero_stats\n    USING DELTA\n    LOCATION '{GOLD_PATH}/hero_stats'\n\"\"\")\n\nspark.sql(f\"\"\"\n    CREATE TABLE IF NOT EXISTS esports_gold.daily_stats\n    USING DELTA\n    LOCATION '{GOLD_PATH}/daily_stats'\n\"\"\")\n\nspark.sql(f\"\"\"\n    CREATE TABLE IF NOT EXISTS esports_gold.ml_features\n    USING DELTA\n    LOCATION '{GOLD_PATH}/ml_features'\n\"\"\")\n\nprint(\"SQL tables created in 'esports_gold' database\")\n\nspark.sql(\"SHOW TABLES IN esports_gold\").show()\n\nprint(\"\\nCSV Samples created:\")\ntry:\n    sample_files = dbutils.fs.ls(f\"{GOLD_PATH}/samples\")\n    for f in sample_files:\n        if f.name.endswith('.csv/'):\n            print(f\"  {f.name}\")\nexcept Exception as e:\n    print(f\"  (No samples directory yet)\")"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}